{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\djaym7\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Data Manipulation\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "#Storing/Loading\n",
    "import pickle\n",
    "import bz2\n",
    "\n",
    "#regular expressions\n",
    "import re\n",
    "import keras\n",
    "#Sklearn, Keras, Nltk\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,CuDNNLSTM,Dropout,Dense,RepeatVector, Activation, Lambda\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data and reading lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!!!\n"
     ]
    }
   ],
   "source": [
    "trainFile='train.ft.txt.bz2'\n",
    "file=bz2.BZ2File(trainFile,'r')\n",
    "lines=file.readlines()\n",
    "print('Done!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "db1099632ab4c93cc07761a469070de6aad75705"
   },
   "outputs": [],
   "source": [
    "docSentimentList=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for splitting the data into Text and Sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "9e5f0cc6f0d42fe3f1325500b59a7bedd5fb5f26"
   },
   "outputs": [],
   "source": [
    "def getDocumentSentimentList(docs,splitStr='__label__'):\n",
    "    t=0\n",
    "    for i in range(len(docs)):\n",
    "        if t==0:print('Processing doc ',i,' of ',len(docs))\n",
    "        text=str(lines[i])\n",
    "        if t==0:print(text)\n",
    "        splitText=text.split(splitStr)\n",
    "        secHalf=splitText[1]\n",
    "        text=secHalf[2:len(secHalf)-1]\n",
    "        sentiment=secHalf[0]\n",
    "        if t==0: print('First half:',secHalf[0],'\\nsecond half:',secHalf[2:len(secHalf)-1])\n",
    "        docSentimentList.append([text,sentiment])\n",
    "        t+=1\n",
    "    print('Done!!')\n",
    "    return docSentimentList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Data\n",
    "First Half shows sentiment = 1 or 2\n",
    "Second Half shows the text review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "1ee9e6484f8cf8169d76577ee3bd590bcc28bf1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing doc  0  of  1000000\n",
      "b'__label__2 Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\\n'\n",
      "First half: 2 \n",
      "second half: Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\\n\n",
      "Done!!\n"
     ]
    }
   ],
   "source": [
    "docSentimentList=getDocumentSentimentList(lines[:1000000],splitStr='__label__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "c60f4fa14aa3a7dbe742e926c9d42fa1a285d855"
   },
   "outputs": [],
   "source": [
    "docDF=pd.DataFrame(docSentimentList,columns=['TEXT','SENTIMENT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example more clearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>SENTIMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>an absolute masterpiece: I am quite sure any o...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Buyer beware: This is a self-published book, a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Glorious story: I loved Whisper of the wicked ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A FIVE STAR BOOK: I just finished reading Whis...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Whispers of the Wicked Saints: This was a easy...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Worst!: A complete waste of time. Typograp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Great book: This was a great book,I just could...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Great Read: I thought this book was brilliant,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Oh please: I guess you have to be a romance no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Awful beyond belief!: I feel I have to write t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Don't try to fool us with fake reviews.: It's ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A romantic zen baseball comedy: When you hear ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fashionable Compression Stockings!: After I ha...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Jobst UltraSheer Thigh High: Excellent product...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sizes recomended in the size chart are not rea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mens ultrasheer: This model may be ok for sede...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Delicious cookie mix: I thought it was funny t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Another Abysmal Digital Copy: Rather than scra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>A fascinating insight into the life of modern ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>i liked this album more then i thought i would...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Problem with charging smaller AAAs: I have had...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Works, but not as advertised: I bought one of ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Disappointed: I read the reviews,made my purch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Oh dear: I was excited to find a book ostensib...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Based on the reviews here I bought one and I'm...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296002</th>\n",
       "      <td>didn't work: I bought the product for my wife ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296003</th>\n",
       "      <td>Gel Start didnt work for my husband: I ordered...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296004</th>\n",
       "      <td>excellent book for a married couple to read to...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296005</th>\n",
       "      <td>Jt at his best: No doubt that Jt Money's first...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296006</th>\n",
       "      <td>THE BITCHIZER RETURNS: STILL THE SAME FROM HIS...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296007</th>\n",
       "      <td>Very nice Plasma: Like many, I did months of r...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296008</th>\n",
       "      <td>Died After 2 Years: At first I loved this TV. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296009</th>\n",
       "      <td>Panasonic TH50 77U plasma: Recently bought the...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296010</th>\n",
       "      <td>Picture is good: The picture on this thing is ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296011</th>\n",
       "      <td>Worst television I've ever owned: I bought thi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296012</th>\n",
       "      <td>Great Product: Got this gift from Santa and Lo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296013</th>\n",
       "      <td>Ineptly made comedy dealing with romantic inde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296014</th>\n",
       "      <td>Don\\' t watch it: Unfortunately this film is t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296015</th>\n",
       "      <td>Not what I had hoped for.: This movie is a who...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296016</th>\n",
       "      <td>Incredible: Think twice before buying Canon L ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296017</th>\n",
       "      <td>Great Lens: I picked up a 5D in March with a 2...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296018</th>\n",
       "      <td>Best General Purpose Walk-Around Lens: That bi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296019</th>\n",
       "      <td>For a L lens I expect higher quality. Error 01...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296020</th>\n",
       "      <td>Great Lens: This is a great lens. My first L l...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296021</th>\n",
       "      <td>Dreaded err01: I used this lens for one shoot,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296022</th>\n",
       "      <td>Bummer: Oh how I wanted to love this lens...I ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296023</th>\n",
       "      <td>Good seller: in the beginning i didn't believe...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296024</th>\n",
       "      <td>Great all-around lens for crop or full frame C...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296025</th>\n",
       "      <td>My Favorite Lens: This lens gives me the benef...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296026</th>\n",
       "      <td>Love it: Its an L lens, contrast is excellent,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296027</th>\n",
       "      <td>Not as good as expected: First off, let me say...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296028</th>\n",
       "      <td>Quality lens: Very good quality lens, feels so...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296029</th>\n",
       "      <td>Haven't used it enough.: Haven't used it enoug...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296030</th>\n",
       "      <td>Canon L Lens at its Best: Got this lens with m...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296031</th>\n",
       "      <td>Great lens: I\\'ve had this lens for 2 months n...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2296032 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      TEXT SENTIMENT\n",
       "0        Stuning even for the non-gamer: This sound tra...         2\n",
       "1        The best soundtrack ever to anything.: I'm rea...         2\n",
       "2        Amazing!: This soundtrack is my favorite music...         2\n",
       "3        Excellent Soundtrack: I truly like this soundt...         2\n",
       "4        Remember, Pull Your Jaw Off The Floor After He...         2\n",
       "5        an absolute masterpiece: I am quite sure any o...         2\n",
       "6        Buyer beware: This is a self-published book, a...         1\n",
       "7        Glorious story: I loved Whisper of the wicked ...         2\n",
       "8        A FIVE STAR BOOK: I just finished reading Whis...         2\n",
       "9        Whispers of the Wicked Saints: This was a easy...         2\n",
       "10       The Worst!: A complete waste of time. Typograp...         1\n",
       "11       Great book: This was a great book,I just could...         2\n",
       "12       Great Read: I thought this book was brilliant,...         2\n",
       "13       Oh please: I guess you have to be a romance no...         1\n",
       "14       Awful beyond belief!: I feel I have to write t...         1\n",
       "15       Don't try to fool us with fake reviews.: It's ...         1\n",
       "16       A romantic zen baseball comedy: When you hear ...         2\n",
       "17       Fashionable Compression Stockings!: After I ha...         2\n",
       "18       Jobst UltraSheer Thigh High: Excellent product...         2\n",
       "19       sizes recomended in the size chart are not rea...         1\n",
       "20       mens ultrasheer: This model may be ok for sede...         1\n",
       "21       Delicious cookie mix: I thought it was funny t...         2\n",
       "22       Another Abysmal Digital Copy: Rather than scra...         1\n",
       "23       A fascinating insight into the life of modern ...         2\n",
       "24       i liked this album more then i thought i would...         2\n",
       "25       Problem with charging smaller AAAs: I have had...         1\n",
       "26       Works, but not as advertised: I bought one of ...         1\n",
       "27       Disappointed: I read the reviews,made my purch...         1\n",
       "28       Oh dear: I was excited to find a book ostensib...         1\n",
       "29       Based on the reviews here I bought one and I'm...         2\n",
       "...                                                    ...       ...\n",
       "2296002  didn't work: I bought the product for my wife ...         1\n",
       "2296003  Gel Start didnt work for my husband: I ordered...         1\n",
       "2296004  excellent book for a married couple to read to...         2\n",
       "2296005  Jt at his best: No doubt that Jt Money's first...         2\n",
       "2296006  THE BITCHIZER RETURNS: STILL THE SAME FROM HIS...         2\n",
       "2296007  Very nice Plasma: Like many, I did months of r...         2\n",
       "2296008  Died After 2 Years: At first I loved this TV. ...         1\n",
       "2296009  Panasonic TH50 77U plasma: Recently bought the...         2\n",
       "2296010  Picture is good: The picture on this thing is ...         2\n",
       "2296011  Worst television I've ever owned: I bought thi...         1\n",
       "2296012  Great Product: Got this gift from Santa and Lo...         2\n",
       "2296013  Ineptly made comedy dealing with romantic inde...         1\n",
       "2296014  Don\\' t watch it: Unfortunately this film is t...         1\n",
       "2296015  Not what I had hoped for.: This movie is a who...         1\n",
       "2296016  Incredible: Think twice before buying Canon L ...         2\n",
       "2296017  Great Lens: I picked up a 5D in March with a 2...         2\n",
       "2296018  Best General Purpose Walk-Around Lens: That bi...         2\n",
       "2296019  For a L lens I expect higher quality. Error 01...         1\n",
       "2296020  Great Lens: This is a great lens. My first L l...         2\n",
       "2296021  Dreaded err01: I used this lens for one shoot,...         1\n",
       "2296022  Bummer: Oh how I wanted to love this lens...I ...         1\n",
       "2296023  Good seller: in the beginning i didn't believe...         2\n",
       "2296024  Great all-around lens for crop or full frame C...         2\n",
       "2296025  My Favorite Lens: This lens gives me the benef...         2\n",
       "2296026  Love it: Its an L lens, contrast is excellent,...         2\n",
       "2296027  Not as good as expected: First off, let me say...         2\n",
       "2296028  Quality lens: Very good quality lens, feels so...         2\n",
       "2296029  Haven't used it enough.: Haven't used it enoug...         2\n",
       "2296030  Canon L Lens at its Best: Got this lens with m...         2\n",
       "2296031  Great lens: I\\'ve had this lens for 2 months n...         2\n",
       "\n",
       "[2296032 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "5b5027e256bb0b113203957103001e5d876d1084",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1161474\n",
       "1    1134558\n",
       "Name: SENTIMENT, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docDF['SENTIMENT'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000000):\n",
    "    if 'www.' in review or 'http:' in review or 'https:' in review or '.com' in docDF['Sentiment'][i]:\n",
    "        docDF['Sentiment'][i] = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", docDF['Sentiment'][i]a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.02187500000000002 \t 2\n"
     ]
    }
   ],
   "source": [
    "z=0\n",
    "print(TextBlob(docDF.TEXT[z]).sentiment.polarity,'\\t',docDF.SENTIMENT[z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "35acd38d2bc309472933764db2335558eb5b3084"
   },
   "outputs": [],
   "source": [
    "X=docDF['TEXT']\n",
    "y=docDF['SENTIMENT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "087dd31c15245248ef33d390f7ba6663d0a4c908"
   },
   "outputs": [],
   "source": [
    "y=y.astype('int32')\n",
    "lb=LabelBinarizer(pos_label=1,neg_label=0)\n",
    "y_binarized=lb.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "3a7671efa86c8efd68b3bcea799439c3d8d5b2c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=to_categorical(num_classes=2,y=y_binarized)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating the polarity, sentiment mismatch reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "#new_df=pd.DataFrame()\n",
    "\n",
    "\n",
    "for i in range(1000000):\n",
    "    polarity = TextBlob(docDF.TEXT[i]).sentiment.polarity\n",
    "    sentiment = docDF.SENTIMENT[i]\n",
    "    if  (polarity>0 and sentiment==1) or(polarity<0 and sentiment==2):\n",
    "        docDF.SENTIMENT[i]=None \n",
    "        docDF.TEXT[i]=None\n",
    "        \n",
    "docDF.dropna(inplace=True)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "e18d3250205e7ed6033f3ec4a15921a61d96ac15"
   },
   "outputs": [],
   "source": [
    "tok=Tokenizer(num_words=100000,lower=True,filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~ \n",
    "',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "629f8ee619c94f32c183c71b3af052db1ce76db3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toekizing...done\n",
      "Sequencing...done\n",
      "Padding sequences...done\n"
     ]
    }
   ],
   "source": [
    "tok.fit_on_texts(X)\n",
    "print('Toekizing...done')\n",
    "seqs=tok.texts_to_sequences(X)\n",
    "print('Sequencing...done')\n",
    "padded_seqs=pad_sequences(seqs,maxlen=100)\n",
    "print('Padding sequences...done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "84dcf4490f32d1bde60658bf4466a31c73eed11a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000000, 100), (1000000, 2))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seqs.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "7bcd327141c78ba1bab98ec0296f31a643069b1a"
   },
   "outputs": [],
   "source": [
    "def createLSTM():\n",
    "    model=Sequential()\n",
    "    model.add(Embedding(20000,100))\n",
    "    model.add(CuDNNLSTM(96,return_sequences=True))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(CuDNNLSTM(128))\n",
    "    #model.add(Dense(500,activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    #model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2,activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    with open('X_train','rb') as f:\n",
    "        X_train = pickle.load(f)\n",
    "    with open('X_test','rb') as f:\n",
    "        X_test = pickle.load(f)\n",
    "    with open('y_train','rb') as f:\n",
    "        y_train = pickle.load(f)\n",
    "    with open('y_test','rb') as f:\n",
    "        y_test = pickle.load(f)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, None, 100)         2000000   \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_15 (CuDNNLSTM)    (None, None, 96)          76032     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, None, 96)          0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_16 (CuDNNLSTM)    (None, 128)               115712    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 2,192,002\n",
      "Trainable params: 2,192,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=loadData()\n",
    "model2=createLSTM()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "5dbc17a4482ce20d789374fd8c4e3b3f449a0886"
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(padded_seqs,y,train_size=0.80,test_size=0.20,random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import pickle\n",
    "with open('X_train','wb') as f:\n",
    "    pickle.dump(X_train,f)\n",
    "with open('X_test','wb') as f:\n",
    "    pickle.dump(X_test,f)\n",
    "with open('y_train','wb') as f:\n",
    "    pickle.dump(y_train,f)\n",
    "with open('y_test','wb') as f:\n",
    "    pickle.dump(y_test,f)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "cd8497473df40c077409bd02ebdbbc8943285083"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800000, 100), (800000, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train),np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800000 samples, validate on 200000 samples\n",
      "Epoch 1/2\n",
      "800000/800000 [==============================] - 2516s 3ms/step - loss: 0.2123 - acc: 0.9156 - val_loss: 0.1745 - val_acc: 0.9327\n",
      "Epoch 2/2\n",
      "800000/800000 [==============================] - 11288s 14ms/step - loss: 0.1566 - acc: 0.9411 - val_loss: 0.1674 - val_acc: 0.9370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2093d046f98>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "model2.fit(X_train,y_train,epochs=2,validation_data=[X_test,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('FInalModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.models.load_model('FInalModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "6317a54eab2744bc53396fd05392a8b3650ef946"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Lucky Dog: I loved this book! Wendy Taylor Carlisle's poems are beautiful, true and deeply moving. Every word seems well-chosen, and nothing's extra. I love the sense the poems give of a real person behind the words--a smart, funny, heartful woman looking unblinkingly at herself and the world, and bravely telling what she sees. I love that the poems aren't afraid to speak in their own voice or to talk about things that matter. I admire Wendy Carlisle's use of form, which is so masterful it seems effortless. I'd recommend this book to both poetry lovers and people who've never read poetry before--the poems here are so inviting, and worth reading and re-reading.\\\\n\"]\n",
      "RESULT:\n",
      "1\n",
      "POS\n"
     ]
    }
   ],
   "source": [
    "idx=np.random.randint(len(X))\n",
    "test=[X[idx]]\n",
    "print(test)\n",
    "print('RESULT:')\n",
    "pred=model2.predict(pad_sequences(tok.texts_to_sequences(test),maxlen=100))\n",
    "print(np.argmax(pred))\n",
    "if np.argmax(pred)==0:\n",
    "    print('NEG')\n",
    "else:\n",
    "    print('POS')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
